"""
This file is to run file generated by ranking_Mturk.py
get the global ranking of questions
"""

import os
import argparse
import pandas as pd
from matplotlib import rcParams
rcParams.update({'figure.autolayout': True})
from fairseq.models.roberta import RobertaModel
import numpy as np
import torch
import torch.nn.functional as F
from sklearn.metrics import mean_squared_error

def get_args():
    parser = argparse.ArgumentParser()
    parser.description = "Running model for ranking questions"

    # load roberta model
    parser.add_argument('-input_name', type=str, default='question')
    parser.add_argument('-model_dir', type=str, default='/home-nfs/users/output/inquisitive'
                                                        '/ranking/HM/source_q1_q2_modify')
    parser.add_argument('-checkpoint_name', type=str, default='checkpoint_best.pt')
    return parser.parse_args()


def predict(tokens, roberta, label_fn):
    tokens_encoded = roberta.encode(tokens)
    scores = roberta.predict('rank_head', tokens_encoded)
    pred = label_fn(scores.argmax().item())
    return int(pred), float(scores[0][0]), float(scores[0][1])


if __name__ == '__main__':
    args = get_args()
    # read data
    df = pd.read_csv('/home-nfs/users/output/inquisitive/MTurk/rc_inquisitive_mturk_input_cssnqt.csv',
                     sep='\t', encoding='utf-8')
    df = df.rename(columns={"Definition": 1, "Background": 2, "Instantiation": 3,
                            "Explanation": 4, "Forward": 5, "Elaboration": 6})
    output_df = df.copy()
    for col in [1, 2, 3, 4, 5, 6]:
        output_df[col].values[:] = 0.
    score_df = output_df.copy()

    # load model
    roberta = RobertaModel.from_pretrained(args.model_dir, checkpoint_file=args.checkpoint_name,
                                           data_name_or_path=args.model_dir.replace('output', 'data'))
    roberta.eval()  # disable dropout
    roberta.cuda()

    # get func
    label_fn = lambda label: roberta.task.label_dictionary.string(
        [label + roberta.task.label_dictionary.nspecial]
    )

    # get predictions
    for row in range(0, df.shape[0]):
        for i in range(1, 7, 1):
            for j in range(1, 7, 1):
                if i != j:
                    sentence = df.at[row, 'sentence'] + ' [SEP] ' + df.at[row, i] + ' [SEP] ' + df.at[row, j]
                    pred, scorei, scorej = predict(sentence, roberta, label_fn)
                    output_df.at[row, i] += pred
                    output_df.at[row, j] += 1 - pred
                    score_df.at[row, i] += scorei
                    score_df.at[row, j] += scorej

    output_df = output_df.rename(columns={1: "Definition", 2: "Background", 3: "Instantiation",
                                          4: "Explanation", 5: "Forward", 6: "Elaboration"})
    output_df.to_csv('/home-nfs/users/output/inquisitive/MTurk/rc_inquisitive_mturk_input_cssnqt_r.csv', sep='\t',
                     encoding='utf-8', index=False)
    score_df = score_df.rename(columns={1: "Definition", 2: "Background", 3: "Instantiation",
                                        4: "Explanation", 5: "Forward", 6: "Elaboration"})
    score_df.to_csv('/home-nfs/users/output/inquisitive/MTurk/rc_inquisitive_mturk_input_cssnqt_s.csv', sep='\t',
                     encoding='utf-8', index=False)





    # df['label'] = pd.read_csv(os.path.join(args.data_path, 'dev.label'), names=['label'], sep='\t', encoding='utf-8')
    # df['pred'] = df['source'].apply(lambda x: predict(x, roberta))
    #
    # # start analyze
    # # F.mse_loss(torch.Tensor(df['label'].to_numpy()), torch.Tensor(df['pred'].to_numpy()), reduction='sum')
    # # np.sqrt(mean_squared_error(df['label'], df['pred']))
    # df['label'] = df['label'] / 4
    # print(mean_squared_error(df['label'], df['pred']))
    # df.to_csv(os.path.join(args.data_path, 'dev_analysis.csv'), index=False, sep='\t', encoding='utf-8')
    #
    # df = pd.read_csv(os.path.join(args.data_path, 'dev_analysis.csv'), sep='\t', encoding='utf-8')
    # print(df)
    # print(df['label'].corr(df['pred'], method='pearson'))
